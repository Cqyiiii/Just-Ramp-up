{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import ChebConv\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as alg\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_connects_cluster(node):\n",
    "    return set(map(lambda x: inverse_cluster_dict[x], list(g[node]))).union(set([inverse_cluster_dict[node]]))\n",
    "\n",
    "def po_linear_model(graph, alpha=1, beta=1, sigma=0.1, gamma=2):    \n",
    "    for i in graph.nodes:\n",
    "        graph.nodes[i][\"y\"] = alpha + beta * graph.nodes[i][\"z\"] + sigma * np.random.normal() + gamma * sum([graph.nodes[ngbr]['z'] for ngbr in graph[i]])/graph.degree[i]  # \n",
    "\n",
    "def po_multiplicative_model(graph, alpha=1, sigma=0.1, delta=1, gamma=2): \n",
    "    for i in graph.nodes:\n",
    "        graph.nodes[i][\"y\"] = ( (alpha + sigma * np.random.normal()) * graph.degree[i]/avg_deg )  *  (1 + delta * graph.nodes[i][\"z\"] + gamma * sum([graph.nodes[ngbr]['z'] for ngbr in graph[i]]) / len(graph[i]) )\n",
    "\n",
    "\n",
    "def po_linear_model_square_expo(graph, alpha=1, beta=1, sigma=0.1, gamma=2):    \n",
    "    for i in graph.nodes:\n",
    "        graph.nodes[i][\"y\"] = alpha + beta * graph.nodes[i][\"z\"] + sigma * np.random.normal() +  gamma * (sum([graph.nodes[ngbr]['z'] for ngbr in graph[i]])/graph.degree[i])**2   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/socfb-Stanford3.mtx'\n",
    "\n",
    "df = pd.read_table(path, skiprows=1, names = [\"source\", \"target\"], sep=\" \")\n",
    "g = nx.from_pandas_edgelist(df)\n",
    "\n",
    "# calculate basic elements\n",
    "num_nodes = g.number_of_nodes()\n",
    "num_edges = g.number_of_edges()\n",
    "degs = [g.degree[i] for i in g.nodes]\n",
    "avg_deg = sum(degs)/len(degs)\n",
    "\n",
    "# clustering\n",
    "# generally, we fix the outcome of clustering\n",
    "clusters = nx_comm.louvain_communities(g, seed = 10, resolution=5)\n",
    "clusters = sorted(clusters, key = len, reverse=True)\n",
    "cluster_sizes = list(map(len, clusters))\n",
    "num_cluster = len(clusters)\n",
    "\n",
    "# dict: from node to its cluster\n",
    "inverse_cluster_dict = {\n",
    "    node: cl for cl in range(num_cluster) for node in clusters[cl]\n",
    "}\n",
    "\n",
    "# dict: from node to its connected cluster\n",
    "node_to_connected_clusters = {\n",
    "    node: node_connects_cluster(node) for node in range(1, num_nodes + 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(nx.adjacency_matrix(g).todense(), dtype = np.float64)\n",
    "deg_array = np.array(list(dict(g.degree).values()))\n",
    "\n",
    "D_inv_A = np.zeros_like(A)\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    D_inv_A[i] = A[i] / deg_array[i]\n",
    "\n",
    "multi_hop_A = torch.load(\"A_2hop.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set diagonal of 2-hop adjacency to 0\n",
    "for i in range(num_nodes):\n",
    "    multi_hop_A[i, i] = 0\n",
    "\n",
    "node_list = list(g.nodes.keys())\n",
    "\n",
    "def po_2hop_linear_model(graph, z_vec, alpha=1, beta=1, sigma=0.1, gamma=1, r1=1, r2=0.5):        \n",
    "    y_vec = alpha + beta * z_vec + sigma * np.random.normal(size=(num_nodes, 1)) + gamma * (\n",
    "    r1 * np.matmul(D_inv_A, z_vec) + r2 * np.matmul(multi_hop_A, z_vec)\n",
    ")\n",
    "    for i in range(num_nodes):\n",
    "        graph.nodes[node_list[i]][\"y\"] = y_vec[i][0]\n",
    "        graph.nodes[node_list[i]][\"z\"] = z_vec[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role of merge data\n",
    "\n",
    "num_repeat = 1000\n",
    "# ramps = [0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "ramps = [0.02, 0.05, 0.1, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 139/1000 [18:33<1:55:15,  8.03s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "ht_array = np.zeros((num_repeat, len(ramps)))\n",
    "\n",
    "for seed in tqdm(range(num_repeat)):\n",
    "    np.random.seed(seed)   \n",
    "\n",
    "    rollout_index = np.random.uniform(0, 1, size=(num_nodes))   \n",
    "    \n",
    "    for num_step in range(len(ramps)):        \n",
    "        p_list = ramps[num_step:]\n",
    "        ht_list = []\n",
    "        for p in p_list:\n",
    "            z = (rollout_index < np.quantile(rollout_index, p))            \n",
    "            nx.set_node_attributes(g, 0, \"z\")\n",
    "            nx.set_node_attributes(g, {unit:1 for unit in range(num_nodes) if z[unit]}, \"z\")   \n",
    "                \n",
    "            po_linear_model(g, gamma = 1)\n",
    "            \n",
    "            # HT estimator\n",
    "            mo1, mo0 = 0, 0\n",
    "            for unit in g.nodes:\n",
    "                if g.nodes[unit]['z'] == 1:\n",
    "                    mo1 += g.nodes[unit]['y']\n",
    "                else:\n",
    "                    mo0 += g.nodes[unit]['y']\n",
    "            HT = (mo1/p - mo0/(1-p))/num_nodes\n",
    "            ht_list.append(HT)\n",
    "        \n",
    "        ht_array[seed, num_step] = sum(ht_list)/len(ht_list)\n",
    "                                    \n",
    "    torch.save(ht_array, \"Result/ht_ramp_unit.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramps = [0.02, 0.05, 0.1, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [45:38<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "ht_array = np.zeros((num_repeat, len(ramps)))\n",
    "\n",
    "for seed in tqdm(range(num_repeat)):\n",
    "    np.random.seed(seed)   \n",
    "\n",
    "    rollout_index = np.random.uniform(0, 1, size=(num_nodes))   \n",
    "    \n",
    "    for num_step in range(len(ramps)):        \n",
    "        p = ramps[num_step]        \n",
    "        z = (rollout_index < np.quantile(rollout_index, p))\n",
    "        \n",
    "        nx.set_node_attributes(g, 0, \"z\")\n",
    "        nx.set_node_attributes(g, {unit:1 for unit in range(num_nodes) if z[unit]}, \"z\")   \n",
    "\n",
    "        po_linear_model(g, gamma = 1)\n",
    "        \n",
    "        # HT estimator\n",
    "        mo1, mo0 = 0, 0\n",
    "        for unit in g.nodes:\n",
    "            if g.nodes[unit]['z'] == 1:\n",
    "                mo1 += g.nodes[unit]['y']\n",
    "            else:\n",
    "                mo0 += g.nodes[unit]['y']\n",
    "        HT = (mo1/p - mo0/(1-p))/num_nodes\n",
    "        ht_list.append(HT)\n",
    "    \n",
    "    ht_array[seed, num_step] = HT\n",
    "                                \n",
    "    torch.save(ht_array, \"Result/ht_incre_unit.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sqaure Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramps = [0.5] # single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [09:10<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ht_array = np.zeros((num_repeat, len(ramps)))\n",
    "\n",
    "for seed in tqdm(range(num_repeat)):\n",
    "    np.random.seed(seed)   \n",
    "\n",
    "    rollout_index = np.random.uniform(0, 1, size=(num_nodes))   \n",
    "    \n",
    "    for num_step in range(len(ramps)):        \n",
    "        p_list = ramps[num_step:]\n",
    "        ht_list = []\n",
    "        for p in p_list:\n",
    "            z = (rollout_index < np.quantile(rollout_index, p))            \n",
    "            nx.set_node_attributes(g, 0, \"z\")\n",
    "            nx.set_node_attributes(g, {unit:1 for unit in range(num_nodes) if z[unit]}, \"z\")                                   \n",
    "            po_linear_model(g, gamma = 1)\n",
    "            \n",
    "            # HT estimator\n",
    "            mo1, mo0 = 0, 0\n",
    "            for unit in g.nodes:\n",
    "                if g.nodes[unit]['z'] == 1:\n",
    "                    mo1 += g.nodes[unit]['y']\n",
    "                else:\n",
    "                    mo0 += g.nodes[unit]['y']\n",
    "            HT = (mo1/p - mo0/(1-p))/num_nodes\n",
    "            ht_list.append(HT)\n",
    "        \n",
    "        ht_array[seed, num_step] = sum(ht_list)/len(ht_list)\n",
    "                                    \n",
    "    torch.save(ht_array, \"Result/Square_ht_ramp_unit.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99952315])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00371132])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_array.std(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
